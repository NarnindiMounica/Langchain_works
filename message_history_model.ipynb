{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f12751",
   "metadata": {},
   "source": [
    "Building a Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d268cf60",
   "metadata": {},
   "source": [
    "This notebook shows how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5920a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "836f7f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000017E5CC92380>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000017E5CC925C0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\", api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "999b49d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Mounica, nice to meet you. LangChain is a great library for building chatbots, it allows for a lot of flexibility and customization. What specific aspects of chatbot building are you interested in learning or implementing with LangChain? Are you working on a project already or just exploring the library?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 53, 'total_tokens': 116, 'completion_time': 0.100512984, 'prompt_time': 0.003738742, 'queue_time': 0.049893428, 'total_time': 0.104251726}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e750f72ec9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--e7440ff1-9e6c-4f66-bbfe-749bb6a35a8c-0', usage_metadata={'input_tokens': 53, 'output_tokens': 63, 'total_tokens': 116})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, I am Mounica. I'm currently learning chatbot building using LangChain\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77d04dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Mounica, and you're learning chatbot building using the LangChain framework.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 152, 'total_tokens': 173, 'completion_time': 0.027406426, 'prompt_time': 0.009794058, 'queue_time': 0.055551662, 'total_time': 0.037200484}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--ee4b60ae-db7c-4137-afe5-dcd8f40dd7e2-0', usage_metadata={'input_tokens': 152, 'output_tokens': 21, 'total_tokens': 173})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, I am Mounica. I'm currently learning chatbot building using LangChain\"), \n",
    "AIMessage(content=\"Hello Mounica, nice to meet you. LangChain is a powerful framework for building chatbots and conversational AI systems. It allows for seamless integration with various language models and enables developers to create more complex and context-aware conversational flows.\\n\\nWhat specific aspects of chatbot building with LangChain are you currently exploring or would like to explore? Are you looking to implement a specific feature or functionality?\"),\n",
    "(HumanMessage(content=\"What's my name and what am i learning\"))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d123c4",
   "metadata": {},
   "source": [
    "Message History\n",
    "\n",
    "* We use message history class to wrap our model and make it stateful. This will keep track of inputs and outputs of model, and store them in some datastore.\n",
    "* Future interactions will then load those messages and pass them into the chain as part of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df593514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "session_store=dict()\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in session_store:\n",
    "        session_store[session_id] = ChatMessageHistory()\n",
    "    return session_store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9529174",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\": {\"session_id\":\"user1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f09f813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" I'm here to help and provide guidance as needed.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 133, 'total_tokens': 145, 'completion_time': 0.01659854, 'prompt_time': 0.009703259, 'queue_time': 0.051164041, 'total_time': 0.026301799}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--48af8c4d-307a-4caf-a904-33aea4bfb31d-0', usage_metadata={'input_tokens': 133, 'output_tokens': 12, 'total_tokens': 145})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke([HumanMessage(content=\"Hi, I am Mounica. I'm currently learning chatbot building using LangChain\"), \n",
    "AIMessage(content=\"Hello Mounica, nice to meet you. LangChain is a powerful framework for building chatbots and conversational AI systems. It allows for seamless integration with various language models and enables developers to create more complex and context-aware conversational flows.\\n\\nWhat specific aspects of chatbot building with LangChain are you currently exploring or would like to explore? Are you looking to implement a specific feature or functionality?\")], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba7940ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Mounica.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 165, 'total_tokens': 173, 'completion_time': 0.004171802, 'prompt_time': 0.010657028, 'queue_time': 0.055175062, 'total_time': 0.01482883}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--7276d55c-a429-4c6e-b712-15d312b9b124-0', usage_metadata={'input_tokens': 165, 'output_tokens': 8, 'total_tokens': 173})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(HumanMessage(content=\"waht is my name?\"), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7daa14f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have any information about your name as this is the start of our conversation. I'm happy to chat with you, though! If you'd like to share your name, I'd be happy to learn it.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 41, 'total_tokens': 87, 'completion_time': 0.064600083, 'prompt_time': 0.003154215, 'queue_time': 0.051373785, 'total_time': 0.067754298}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e750f72ec9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--fedf49c2-96e0-48c7-9c1a-9dcecb9dc66a-0', usage_metadata={'input_tokens': 41, 'output_tokens': 46, 'total_tokens': 87})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2={\"configurable\":{\"session_id\":\"user2\"}}\n",
    "with_message_history.invoke(\"waht is my name?\", config=config2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650c71ed",
   "metadata": {},
   "source": [
    "since session_id is different and different config is passed now, it's not able to recognize name of user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d741f0dd",
   "metadata": {},
   "source": [
    "Working with prompt template and message chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4af72974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer all the questions to the best of your ability in selected language: {language}\"), \n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09368688",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7568e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "config3 = {\"configurable\": {\"session_id\": \"user3\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c87f3361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='नमस्ते मुनिका! मैं आपकी सहायता करने के लिए तैयार हूँ। क्या मैं आपकी किसी भी समस्या या प्रश्न का समाधान कर सकता हूँ?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 64, 'total_tokens': 125, 'completion_time': 0.068396814, 'prompt_time': 0.004152551, 'queue_time': 0.054156769, 'total_time': 0.072549365}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e750f72ec9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--e2e0e441-e6dd-443a-90c0-56c2e540e984-0', usage_metadata={'input_tokens': 64, 'output_tokens': 61, 'total_tokens': 125})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke({\"language\":\"hindi\", \"messages\":\"Hi, My name is Mounica\"}, config=config3)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aebdab0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='నీవు ఎవరు? నీ పేరు మౌనికా.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 140, 'total_tokens': 183, 'completion_time': 0.081903735, 'prompt_time': 0.008378472, 'queue_time': 0.054399767, 'total_time': 0.090282207}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e750f72ec9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--1bdd94b5-75a2-4f94-8559-d0854baac240-0', usage_metadata={'input_tokens': 140, 'output_tokens': 43, 'total_tokens': 183})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= with_message_history.invoke({\"language\":\"telugu\", \"messages\":\"what is my name?\"}, config=config3)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce49b99",
   "metadata": {},
   "source": [
    "Managing the conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "362fbc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableLambda(...)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, trim_messages, SystemMessage, AIMessage\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=50,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    allow_partial=True,\n",
    "    start_on=\"human\",\n",
    "    include_system=True\n",
    "\n",
    ")\n",
    "\n",
    "trimmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a7e81b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are a good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi, Im John here', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi John, Nice to meet you', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like Mangoes', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Great', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 2 multiple 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='it is 4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ok, Thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='No problem', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes of course!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=[\n",
    "    SystemMessage(content=\"you are a good assistant\"),\n",
    "    HumanMessage(content=\"Hi, Im John here\"),\n",
    "    AIMessage(content=\"Hi John, Nice to meet you\"),\n",
    "    HumanMessage(content=\"I like Mangoes\"),\n",
    "    AIMessage(content=\"Great\"),\n",
    "    HumanMessage(content=\"what is 2 multiple 2\"),\n",
    "    AIMessage(content=\"it is 4\"),\n",
    "    HumanMessage(content=\"ok, Thanks\"),\n",
    "    AIMessage(content=\"No problem\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes of course!\")\n",
    "    \n",
    "]\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1debd563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are a good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like Mangoes', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Great', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 2 multiple 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='it is 4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ok, Thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='No problem', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes of course!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2a3d35",
   "metadata": {},
   "source": [
    "Using trimmer along with chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d8fb0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
    "| prompt\n",
    "| model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "051e5ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Unfortunately, I'm a large language model, I don't have the ability to retain information or recall previous conversations. Each time you interact with me, it's a new conversation.\\n\\nHowever, I can suggest that if you'd like to discuss a math question, you can share it with me now and I'll do my best to help you solve it. What's the math question you'd like to ask?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 65, 'total_tokens': 148, 'completion_time': 0.103026067, 'prompt_time': 0.004485213, 'queue_time': 0.050179847, 'total_time': 0.10751128}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--b4f3d92e-b2b9-4c5d-adf4-3126c907a4e6-0', usage_metadata={'input_tokens': 65, 'output_tokens': 83, 'total_tokens': 148})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"what is maths question which I was speaking previously\")], \"language\":\"english\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chainvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
